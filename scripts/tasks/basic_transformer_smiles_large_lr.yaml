# project
task_name: "basic_transformer_smiles_large_lr"
device: "cuda"
train_data_path: "finetune/runtime/datasets_seed_0/finetune_train_smiles.csv"
val_data_path: "finetune/runtime/datasets_seed_0/finetune_val_smiles.csv"
word_table_path: "all/smiles_word_table.yaml"
data_format: "SMILES"

# train
learning_rate: 5.0e-4
min_learning_rate: 1.0e-6
# warming_steps * bsz / all_size = proportion
warming_step: 72200   # 100% epoch
weight_decay: 1.0e-5
batch_size: 64
epoch_num: 5
log_interval: 50
save_interval: 40

# model
max_len: 250
left_pad: False
d_model: 512
n_head: 8
d_enc_ffn: 1024
d_dec_ffn: 1024
enc_n_layer: 3
dec_n_layer: 4
enc_dropout: 0.2
dec_dropout: 0.2
enc_embed_dropout: 0.15
dec_embed_dropout: 0.15
enc_relu_dropout: 0.1
dec_relu_dropout: 0.1
enc_attn_dropout: 0.15
dec_attn_dropout: 0.15
seed: 42