# project
task_name: "train_core_transformer"
device: "cuda"
train_data_path: "atom/runtime/atom_train.csv"
val_data_path: "atom/runtime/atom_val.csv"
word_table_path: "all/smiles_word_table.yaml"
data_cols: ["mol_a_smiles", "atoms"]

# train
learning_rate: 1.0e-4
min_learning_rate: 1.0e-6
# warming_steps * bsz / all_size = proportion
warming_step: 65679   # 200% epoch
weight_decay: 1.0e-5
batch_size: 128
epoch_num: 20
log_interval: 50
seed: 42
save_interval: 1

# model
max_len: 250
left_pad: False
d_model: 512
n_head: 8
d_enc_ffn: 1024
d_dec_ffn: 1024
enc_n_layer: 3
dec_n_layer: 4
enc_dropout: 0.2
dec_dropout: 0.2
enc_embed_dropout: 0.15
dec_embed_dropout: 0.15
enc_relu_dropout: 0.1
dec_relu_dropout: 0.1
enc_attn_dropout: 0.15
dec_attn_dropout: 0.15